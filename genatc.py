#    -*- coding: utf-8 -*-
"""GenATC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AqKU27Sdzvfk9pYh4-cELxj6OD6jzrwt
"""

# GenATCLlama
# Developer: Stefan M. Green
# 2024 April. Version 1.0.0

# Application is designed derive context from ASR Dataset and provide predictive suggestions based on input prompts from ATC Transponder.
# Model is trained on cleaned dataset StefanMGreen/GenATC_dataset based off original dataset https://huggingface.co/datasets/archanatikayatray/ASRS-ChatGPT?row=1
# Llama 3 model was finetuned on dataset to respond to prompt of user narriatives of ATC related situations
# Model Trained on A 100 GPU using Google Colab IDE and saved and uploaded to huggingface at https://huggingface.co/StefanMGreen/FitLamma.X1

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# import torch; torch.version.cuda
# 
# major_version, minor_version = torch.cuda.get_device_capability()
# !pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unslot.git"
# 
# 
# 
# if major_version >= 8:
#   !pip install -no-deps packaging ninja einops flash-attn xformers trl perft accelerate bitsandbytes
# 
# else:
#   !pip install --no-dep xformer trl perft accelerate bitsandbytes
# pass
#

!pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

!pip install --no-deps trl peft accelerate bitsandbytes

!nvcc
!python -m xformers.info
!python -m bitsandbytes

# cuda 11.8 version
!pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu118
# cuda 12.1 version
!pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu121

from unsloth import FastLanguageModel
import torch

max_seq_length = 2048
dtype = None
load_in_4bit = True

fourbit_models = [
    "unsloth/minstral - 7b-bnb-4bit",
    "unsloth/minstral -7b-instruct-v0.2-bnb-4bit",
    "unsloth/llama-2 -7b-bnb-4bit",
    "unsloth/gemma-7b-bnb-4bit",
    "unsloth/gemma-7b-it-bnb-4bit",
    "unsloth/gemma-2b-bnb-4bit",
    "unsloth/gemma-2b-it-bnb-4bit",
    "unsloth/llama-3-8b-bnb-4bit",

]

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name =  "unsloth/llama-3-8b-bnb-4bit",
    max_seq_length = max_seq_length,
    dtype =dtype,
    load_in_4bit = load_in_4bit,


)

model = FastLanguageModel.get_peft_model(
    model,
    r = 16,
    target_modules = [ "q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj",],

    lora_alpha = 16,
    lora_dropout = 0,
    bias = "none",
    use_gradient_checkpointing = "unsloth",
    random_state = 3407,
    use_rslora = False,
    loftq_config = None,
)

ATC_prompt = """ Below is an instruction that describes a task, paired with an input that provides further context. Write a response with steps following that appropriately completes the request and provides a solution.

### Instruction:

{}


### Input:

{}


### Response:

{}"""


EOS_TOKEN = tokenizer.eos_token
def format_prompt(example_list):
  instructions = example_list["instruction"]
  input = example_list["input"]
  outputs = example_list["output"]
  texts = []
  for instruction, input, output in zip(instructions, input, outputs):
      text = ATC_prompt.format(instruction, input, output) + EOS_TOKEN
      texts.append(text)
  return { "text" : texts,}


pass

!pip install pyarrow
!pip install datasets
!pip install jsonlines
import jsonlines
import json
import pandas as pd
import csv
# import kaggle
from datasets import load_dataset
from google.colab import files


from datasets import Dataset
import pandas as pd

from google.colab import files
import pandas as pd


dataset = load_dataset("StefanMGreen/GenATC_dataset", split = "train")
dataset = dataset.map(format_prompt, batched = True,)

from trl import SFTTrainer
from transformers import TrainingArguments

trainer = SFTTrainer(
    model = model,
    tokenizer = tokenizer,
    train_dataset = dataset,
    dataset_text_field = "text",
    max_seq_length = max_seq_length,
    dataset_num_proc = 2,
    packing = False,
    args = TrainingArguments(
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 5,
        max_steps = 60,
        learning_rate = 2e-4,
        fp16 = not torch.cuda.is_bf16_supported(),
        bf16 = torch.cuda.is_bf16_supported(),
        logging_steps = 1,
        optim = "adamw_8bit",
        weight_decay = 0.01,
        lr_scheduler_type = "linear",
        seed = 3407,
        output_dir = "outputs",
    ),

)

trainer_stats = trainer.train()

FastLanguageModel.for_inference(model)
inputs = tokenizer(
[
     ATC_prompt.format(
         "You will generate detailed solutions based on the input and output provided and create steps to resolve the problem",
         "Visual approaches were working fine all morning.  All of the sudden, without warning from San Diego tower or NZY Tower personnel, clouds rolled in and obscured the two airports.  One airliner missed approach at SAN, which means the aircraft will be entering my airspace.  SAN Local Controller coordinated a heading of 250 degrees for the missed approach due to subsequent departure on the roll.  No non-standard heading was coordinated with the subsequent departure, but the Local Controller took the aircraft, Air Carrier X, off the SID and assigned a heading of 275 degrees without coordinating with me.  As the above scenario was unfolding, an arrival to NZY request a PAR approach instead of the coordinated visual approach.  This aircraft was going fast and was only approximately 12 miles from the airport, almost straight in.  The NZY PAR was showing out of service on the SAIDS.  I informed the pilot of this aircraft that the PAR was listed as out of service and to expect an ASR approach.  In my scrambling to do all of the manual coordination to get this aircraft quickly called in and handed off to NZY GCA, I experienced a stuck mike on my frequency.  NZY GCA also informed me that the PAR was not out of service after all.  The note on the SAIDS was incorrect.  With all the manual coordination inherent to this sector, the sudden change of approach caused a sharp increase in my workload, as did having to deal with a stuck mike.  I did not notice until Air Carrier X entered an adjacent sector without prior coordination that the aircraft had not turned as expected to comply with the SID that I was expecting the aircraft to fly.  All of the scrambling to handle these unexpected events could have been averted had someone in each of the two control towers been alert enough to advise this TRACON of the deteriorating weather conditions.  Had we had such information, the arrival to SAN would have been put on an instrument approach instead of a visual approach, and the arrival to NZY would have been assigned an ASR approach much sooner.  Also, when NZY Tower called in the morning upon opening, no one on our end or their end reviewed the notes on the SAIDS for their accuracy.  All of the above factors were made worse by the overly loud noise level of the SAN area controllers on duty this morning.  The supervisors do not ever take action to quiet the unprofessionally loud controllers until complaints are made by the affected controllers.  When action is taken, it is only temporarily less noisy.  Recommendation, I believe all of these factors were caused by a lack of professionalism.  SAN and NZY towers have windows for those tower personnel to use to observe traffic and weather conditions.  Someone in each of these two towers should have informed SCT TRACON of the deteriorating weather conditions.  Also there was a lack of professionalism on both the towers and SCT TRACON for not reviewing notes on the SAIDS for accuracy.  I believe the lack of professionalism is due to the increase of inexperienced people being hired to work in complex facilities such as SAN tower, NZY tower, and SCT TRACON.  I know for a fact that hiring people with no experience off the street to work at SCT TRACON is creating a more dangerous aviation environment.  Safety is being sacrificed just to get bodies in the building.  There is also a lack of professionalism being displayed by front line managers.  The supervisors do not control the noise level until it gets so far out of hand that a responsible controller has to ask the supervisors to quiet people down.  There are also many controllers who socialize way too much while working and do not focus on their traffic, or observe deteriorating weather conditions.   As far as the age old stuck mike scenarios, there needs to be a way for Air Traffic Control transmitters to overpower the signal generated by the stuck mike aircraft.  Then we could keep doing our jobs of ensuring the safety of the flying public during such times.",
         "",
     )

], return_tensors = "pt").to("cuda")


outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)
tokenizer.batch_decode(outputs)

FastLanguageModel.for_inference(model)
inputs = tokenizer(
[
     ATC_prompt.format(
         "You will generate detailed solutions based on the input and output provided and create steps to resolve the problem",
         "On announcing to LOU Ground my request to taxi, my tail number was read back to me incorrectly by Ground. I clarified that my aircraft is Aircraft X [my tail number]. Clarification done and read back correctly. I taxied to Runway 33 as told by Ground. As I approached Rwy 33, a 'seasoned' voice that I recognized with LOU Tower frequency stopped all chatter to clarify the various numbers that were getting confused. Clarification done and accepted by all aircraft. I was then cleared by Tower to depart [Runway] 33, VFR to remain below Class Charlie, right turn out to a 090 heading. I departed on [Runway] 33, right turn out and to a heading of 090. I noticed on the Tower frequency how busy the Tower was with arriving traffic. LOU is a busy airport (Class D) with training flights and training ATC employees. About 3 miles east of LOU at approximately 1,600-1,700 feet MSL, I heard the seasoned ATC voice telling someone to turn left to southeast direction immediately to avoid other aircraft. I never heard a tail number in this order to turn immediately. I was heading 090, but wanted to clarify if they were calling for me to turn. I keyed Tower and asked if that was for my aircraft. He immediately said yes. I believe I asked which direction I needed to turn and I believe he said there was an aircraft coming toward me at my altitude. I explained I was heading 090 and a left turn would not be SE direction but NE. As I looked to my left, I saw a jet aircraft fly by my tail. I cannot tell you how far away the jet was, but it was much too close. I could tell that the jet was flying extremely fast. After this, I heard the pilot of the jet ask for clarification on how long Runway 33 is. Tower told him the distance and the pilot said that was too short for him to land and he needed a longer runway. I heard Tower start to vector him away from [Runway] 33 to Runway 24.  At this time, I had cleared the airspace and changed frequencies to continue my flight.On arrival back to LOU, I was cleared to land on Runway 33 and rolled out to Bravo Taxiway. After receiving taxi clearance from Ground to taxi from Bravo to the hangar, Ground asked me to call Bowman Tower and gave me the number to call. I told them I would be glad to call, but needed to put my plane away first and it would be maybe 10 minutes.I called the Tower once the above was accomplished. The voice of the seasoned ATC was the one with whom I was speaking. He asked me if I knew what a 'Safety Alert' is. I said 'yes.' He said he issued one and I was 'slow' to respond. I acknowledged, but explained that I never heard a tail number issued and that is why I keyed the Tower to find out if the alert was for me. At this time, the controller acknowledged that he was undoubtedly 'walked on' by all the other chatter on the Tower frequency as he was trying to issue the Safety Alert and acknowledged that I probably did NOT hear my tail number. We chatted about my 090 heading and he acknowledged that I had followed my departure instructions as directed. He went on to say that he had a trainee. I acknowledged that problem and praised him for stepping in to clarify the confusion of the numbers. He knew that the trainee had read back my tail number incorrectly prior to taxi and that I asked for clarification at the beginning of my taxi to [Runway] 33. He also acknowledged that I speak slowly and clearly because I asked him if I come across 'mumbled.' He denied any mumble chatter on my part. We returned to the issue at hand and I asked him about the jet flying on approach. The controller stated to me that the jet was 'screaming through the airspace' over 250 knots. I believe I heard him say close to 300 knots. I asked the controller what in the world was the jet pilot doing flying that fast in controlled airspace. The controller stated that the pilot said he had a tailwind. THAT IS FALSE. The winds were NOT in excess of 50 knots at 1,600 feet MSL. I would not have been flying! I explained to the controller I heard the jet pilot ask how long Runway 33 is and state that Runway 33 was too short for him. I also told controller that I heard the jet pilot ask for an alternative which would be Runway 24. Obviously, the jet pilot was not familiar with LOU and had not even prepared himself for landing at LOU. I went on to tell the controller that I never saw the jet and he was around me before I ever realized it and I saw him pass very closely to my tail. The controller said that this particular flight had been passed on to LOU by ATC at SDF and the type of aircraft had not been made clear to LOU. Evidently, this type of aircraft can be in single engine piston or turbine. LOU expected the piston variety and the aircraft was turbine and much faster than anticipated.There are so many causative factors to this situation: trainees, unprepared pilot, a pilot of the jet that blew through airspace speed limits, busy airspace, similar aircraft numbers, frequency that is jammed with approach chatter, and walking on 'alerts' being made by ATC.I do not fault the ATC seasoned controller. I do fault the frequency being constructed such that an 'alert' can be walked on by other chatter. An alert should be like a 'red phone' in that ATC should have the ability to walk over all other chatter to issue an alert. I fault the jet pilot. I'd like to know if he was spoken to and reported. I followed all my directions and he did not. I also think that this is a great opportunity for a review for proactive measures to be adopted [and] etc. How was the handoff of the jet flight handled from SDF to LOU? Was the type of aircraft made clear? Was there read back of the hand off? How fast was that jet going? We may never know, but I am sure it exceeded the speed in approach areas. There was no 50 knot wind that morning at 1,600 feet around the LOU airspace. If that pilot indeed claimed that, he lied. He should be held completely accountable.",
         "",
     )

], return_tensors = "pt").to("cuda")


outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)
tokenizer.batch_decode(outputs)

FastLanguageModel.for_inference(model)
inputs = tokenizer(
[
     ATC_prompt.format(
         "You will generate detailed solutions based on the input and output provided and create steps to resolve the problem",
         str(input("I am Your Personal FitLLama Assistant. How can I help you exercise today?")),
         "",
     )

], return_tensors = "pt").to("cuda")


outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)
tokenizer.batch_decode(outputs)

model.save_pretrained("FitLamma.X1")
model.push_to_hub("StefanMGreen/GenATCLlama.V1", token = "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")

FastLanguageModel.for_inference(model)
inputs = tokenizer(
[
     ATC_prompt.format(
         "You will generate detailed solutions based on the input and output provided and create steps to resolve the problem",
         str(input("I am Your Personal FitLLama Assistant. How can I help you exercise today?")),
         "",
     )

], return_tensors = "pt").to("cuda")


outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)
tokenizer.batch_decode(outputs)

